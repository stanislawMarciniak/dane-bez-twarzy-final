# =========================================================================
# WYNIKI WYDAJNOŚCI I KONFIGURACJA ŚRODOWISKA
# Zespół: Overfitters
# Data: 07.12.2025
# =========================================================================

# 1. METRYKI CZASOWE (Kryterium: Czas przetwarzania od odczytu do zapisu. Nie wliczamy czasu ładowania bibliotek/modeli.)

TIME: 129.801

# Szczegółowy podział czasów:
# - Warstwa ML (NER):           129.421 s  │ avg: 408.27 ms/sample
# - Warstwa Regex:                0.134 s  │ avg: 424.2 µs/sample
# - Detailed Labels:              0.209 s  │ avg: 659.7 µs/sample
# - Generacja syntetyczna:        0.019 s  │ avg:  60.2 µs/sample
# - Zapis plików (I/O):           0.017 s
#
# Czas do output_Overfitters.txt:            129.571 s
# Czas do synthetic_generation_Overfitters:  129.801 s
#
# Liczba próbek (linii):  317
# Średni czas per sample: 409.47 ms


# 2. SPRZĘT (HARDWARE)

Hardware:
Typ: CPU
Model: 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz (4 rdzenie, 8 procesorów logicznych)
Pamięć RAM: 16 GB

# Uwagi:
# - Model działał na CPU (brak dedykowanego GPU)
# - Batch size: 32
# - Device: -1 (CPU mode)


# 3. KONFIGURACJA MODELI I API

API: NIE
# NIE użyto API PLLUM ani własnego modelu postawionego na zewnętrznym serwerze.

Model NER: Custom BERT (HerBERT fine-tuned)
# Model token-classification wytrenowany na polskich danych NER
# Lokalizacja: ./models/
# Aggregation strategy: simple

Moduł Fleksyjny: Morfeusz2
# Morfeusz2 jest wykorzystywany lokalnie, w pełni offline, jako kluczowy element pipeline'u do tagowania i syntezy.

Inne narzędzia:
# - Biblioteka Rapidfuzz do mapowania tokenów
# - Transformers (HuggingFace) do obsługi modelu NER
# - PyTorch jako backend


# 4. ARCHITEKTURA PIPELINE'U

# Kolejność przetwarzania:
# 1. Model ML (NER) - wykrywa encje: name, surname, age, sex, city, address, phone, email, pesel, date, relative, job-title, company, school-name, health, religion, political-view, ethnicity, sexual-orientation, bank-account, credit-card-number, document-number, username, secret
# 2. Regex Layer - łapie wzorce: email, PESEL, telefony, numery kont, numery kart
# 3. Zapis do output_Overfitters.txt
# 4. Detailed Labels - dodaje info o płci i przypadku gramatycznym
# 5. Synthetic Generator - generuje dane syntetyczne z odmianą fleksyjną
# 6. Zapis do synthetic_generation_Overfitters.txt
